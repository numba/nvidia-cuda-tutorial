{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.2 - The vectorize decorator\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- See how to write vectorized functions and observe how type inference behaves\n",
    "- See how to control the selection of types for vectorized functions\n",
    "- Call ufunc methods\n",
    "- Understand the performance of vectorized functions compared to array expressions\n",
    "\n",
    "## Our first vectorized function\n",
    "\n",
    "Let's define an elementwise function for computing the relative difference of two numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize\n",
    "def rel_diff(x, y):\n",
    "    return 2 * (x - y) / (x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have written our `rel_diff` function in terms of a scalar, but because we have used the vectorize decorator, we can apply the function to an array. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.arange(10, dtype=np.float64)\n",
    "b = a * 2 + 1\n",
    "\n",
    "diff = rel_diff(a, b)\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the output that the function has been applied element-wise.\n",
    "\n",
    "Inspect the dtype of the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dtype was inferred based on the dtypes of the input arrays.\n",
    "\n",
    "## Numba’s choice of types\n",
    "\n",
    "Try running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@vectorize\n",
    "def prod(x, y):\n",
    "    return x * y\n",
    "\n",
    "a_int = np.arange(1000, dtype=np.int32)\n",
    "b_int = a_int * 2\n",
    "\n",
    "result = prod(a_int, b_int)\n",
    "\n",
    "result.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the dtype of the result is not the same as the input array’s dtype! Instead, Numba has decided that the output array should be of dtype int64 - this is because the multiplication of two int32 values could overflow an int32 output, and Numba tries to avoid this scenario.\n",
    "\n",
    "To continue the example, try calling the function on some arrays of other types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_f64 = np.arange(1000, dtype=np.float64)\n",
    "b_f64 = a_f64 * 2\n",
    "result2a = prod(a_f64, b_f64)\n",
    "\n",
    "a_f32 = np.arange(1000, dtype=np.float32)\n",
    "b_f32 = a_f32 * 2\n",
    "result2b = prod(a_f32, b_f32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the dtypes of these two results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result2a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result2b.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dtypes of both results are the same. However, in this case, it is because the vectorized function was first executed on arguments with `float64` dtypes, which created a compiled version of the `prod` function with the signature `float64(float64, float64)`.\n",
    "\n",
    "When the function is called with arguments with a dtype of `float32`, the version that takes `float64` arrays is seen by Numba, and it will cast the `float32` inputs to `float64` then make use of the previously-compiled code.\n",
    "\n",
    "In order to see what types a vectorized function has been compiled for, you can use its `ufunc.types` member:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prod.ufunc.types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output notation, `i` means `int32`, `l` means `int64`, and `d` means `float64`. For example, the notation `ii->l` describes the mapping of two `int32` values to an `int64` value. You should see a version that accepts `int32` parameters and another version that accepts `float64` parameters.\n",
    "\n",
    "## Ensuring the use of specific types\n",
    "\n",
    "Although it is often convenient and acceptable to allow Numba to determine the signatures for vectorized functions, it is sometimes desirable to specify the types exactly in order to avoid situations such as those above occurring.\n",
    "\n",
    "The vectorize decorator will accept a list of signatures, in order of precedence. Continuing the above example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import int32, int64, float32, float64\n",
    "\n",
    "@vectorize([int32(int32, int32),\n",
    "            int64(int64, int64),\n",
    "            float32(float32, float32),\n",
    "            float64(float64, float64)])\n",
    "def prod2(x, y):\n",
    "    return x * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba will check each signature in order to see if it matches the arguments to a function call. It is important that most-specific types are higher up in the list than less specific types. For example, `float32` must be before `float64` because `float64` will always match `float32`.\n",
    "\n",
    "Verify that the `prod2` function behaves as you expect by calling it with arguments that are of the `int32` and `float32` dtypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_i32 = np.arange(1000, dtype=np.int32)\n",
    "b_i32 = np.arange(1000, dtype=np.int32)\n",
    "prod2(a_i32, b_i32).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_f32 = np.arange(1000, dtype=np.float32)\n",
    "b_f32 = np.arange(1000, dtype=np.float32)\n",
    "prod2(a_f32, b_f32).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ufunc methods\n",
    "\n",
    "Why not just write functions using the jit decorator that include a for-loop over the input arguments? One answer to this question is that creating ufuncs also provides additional methods with no extra work. The following code demonstrates the reduce and accumulate functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.arange(12).reshape(3,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prod2.reduce(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prod2.reduce(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prod2.accumulate(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not familiar with ufuncs, run the above code and examine the output to understand what is happening in these functions. For full documentation of the ufunc methods, refer to http://docs.scipy.org/doc/numpy/reference/ufuncs.html#methods\n",
    "\n",
    "## Ufunc performance\n",
    "\n",
    "Why not combine Numpy’s built-in ufuncs in order to achieve the same result as using the vectorize decorator on a function? In many cases (especially those with complex behaviour or control flow) it is much easier to write a scalar function than to try to write the entire computation as array-wide expressions.\n",
    "\n",
    "For those cases where it is straightforward to write array-wide expressions, the performance of vectorize-decorated function soon overtakes the pure Numpy implementations. Try running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(100000, dtype=np.float64) + 1\n",
    "y = np.arange(100000, dtype=np.float64) + 1.1\n",
    "\n",
    "%timeit 2 * (x - y) / (x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit rel_diff(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results will vary depending on your machine, but on one machine execution times were 2.1ms for Numpy and 1.25ms for the Numba-compiled function. There are two main reasons for this:\n",
    "\n",
    "- Memory allocation: Numpy will create a temporary array for each intermediate step in the computation\n",
    "- Cache thrashing: because each operation is performed on a whole temporary array at a time, data is repeatedly evicted-from and reloaded into the CPU cache, which reduces performance.\n",
    "\n",
    "The Numba-compiled function performs all computations on a single element at a time, which sidesteps these issues.\n",
    "\n",
    "# Summary\n",
    "\n",
    "- The vectorize decorator is used to turn a scalar function into one which can be applied to all elements of an array.\n",
    "- Type inference is performed on the arguments to determine the output types.\n",
    "- However, a version previously-compiled may be used if the arguments can be coerced into a suitable type.\n",
    "- In order to control the coercion and any casting, input and output types can be specified as arguments to the vectorize decorator.\n",
    "- Vectorized functions also get additional methods, such as `reduce`, for \"free\".\n",
    "- Performance of a vectorized function is generally higher than writing the equivalent array expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
